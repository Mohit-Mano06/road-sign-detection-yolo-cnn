{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Found 4222 images.\n",
      "Label: 0, Image shape: (32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcq0lEQVR4nO3dW6xdBbn28WeMMU9rra4CLS1b3VF3g4LdYj5jAS9qKGqCBBMhQS4NN1yIF8SIx0TAxGhI5BDFA/EQNFwpQWOi0WQHe8emEIN+uEUr0i+bg9DjOs/DOHwX4BvZRXifTSt07/8v4aa8fTvWGGPOZ05gPBRd13UCAEBS+WofAADgtYNQAAAEQgEAEAgFAEAgFAAAgVAAAARCAQAQCAUAQCAUAACBUMD/SAcOHFBRFPrKV75ywnbu3btXRVFo7969J2wn8FpDKOA146677lJRFHrooYde7UM5aZ588kldddVVOv3007V582Z96EMf0p///OdX+7CA0Hu1DwD432J1dVUXX3yxlpaW9LnPfU79fl+33XabLrroIj388MPaunXrq32IAKEA/KN84xvf0P79+7Vv3z6df/75kqRLL71Ub3/723XLLbfoS1/60qt8hAD/+AinmOl0qhtuuEHvete7dNppp2lhYUHvec979Ktf/erv/p7bbrtNb3rTmzQ3N6eLLrpIjzzyyHEzjz76qK688kpt2bJFo9FIu3bt0k9/+tOXPZ719XU9+uijOnTo0MvO3nPPPTr//PMjECTp3HPP1fve9z798Ic/fNnfD/wjEAo4pSwvL+s73/mO9uzZo5tvvlk33XSTDh48qEsuuUQPP/zwcfM/+MEP9NWvflUf+9jH9NnPflaPPPKI3vve9+qZZ56Jmd/97nd697vfrd///vf6zGc+o1tuuUULCwu6/PLL9eMf//glj2ffvn1629vepjvuuOMl59q21W9/+1vt2rXruL93wQUX6LHHHtPKykruJAAnEf/4CKeUM844QwcOHNBgMIhfu+aaa3Tuuefqa1/7mr773e++YP5Pf/qT9u/frze84Q2SpA984AO68MILdfPNN+vWW2+VJF133XV64xvfqAcffFDD4VCSdO2112r37t369Kc/rSuuuOIVH/eRI0c0mUz0ute97ri/99dfe+qpp3TOOee84j8LeCX4poBTSlVVEQht2+rIkSOq61q7du3Sr3/96+PmL7/88ggE6blP5RdeeKF+/vOfS3ruzfq+++7TVVddpZWVFR06dEiHDh3S4cOHdckll2j//v168skn/+7x7NmzR13X6aabbnrJ497Y2JCkCJ2/NRqNXjADvJoIBZxyvv/97+sd73iHRqORtm7dqm3btulnP/uZlpaWjpt9y1vectyvvfWtb9WBAwckPfdNous6ff7zn9e2bdte8NeNN94oSXr22Wdf8THPzc1JkiaTyXF/bzwev2AGeDXxj49wSrn77rt19dVX6/LLL9cnP/lJbd++XVVV6ctf/rIee+wxe1/btpKk66+/XpdccsmLzpx99tmv6JglacuWLRoOh3r66aeP+3t//bXXv/71r/jPAV4pQgGnlHvuuUc7duzQvffeq6Io4tf/+qn+v9q/f/9xv/bHP/5Rb37zmyVJO3bskCT1+329//3vP/EH/LyyLHXeeee96IN5DzzwgHbs2KHFxcWT9ucDWfzjI5xSqqqSJHVdF7/2wAMP6P7773/R+Z/85Ccv+HcC+/bt0wMPPKBLL71UkrR9+3bt2bNHd95554t+ij948OBLHo/zn6ReeeWVevDBB18QDH/4wx9033336cMf/vDL/n7gH4FvCnjN+d73vqdf/OIXx/36ddddpw9+8IO69957dcUVV+iyyy7T448/rm9961vauXOnVldXj/s9Z599tnbv3q2PfvSjmkwmuv3227V161Z96lOfipmvf/3r2r17t8477zxdc8012rFjh5555hndf//9euKJJ/Sb3/zm7x7rvn37dPHFF+vGG2982X/ZfO211+rb3/62LrvsMl1//fXq9/u69dZbddZZZ+kTn/hE/gQBJxGhgNecb37zmy/661dffbWuvvpq/eUvf9Gdd96pX/7yl9q5c6fuvvtu/ehHP3rRorqPfOQjKstSt99+u5599lldcMEFuuOOO17wn4bu3LlTDz30kL7whS/orrvu0uHDh7V9+3a9853v1A033HDCfq7FxUXt3btXH//4x/XFL35Rbdtqz549uu2227Rt27YT9ucAr0TR/e33cADA/2r8OwUAQCAUAACBUAAABEIBABAIBQBAIBQAACH9nMKXb/62tXhW1+nZSTO1dpdVfnY4N3j5ob+dH+Uf3RgNvcc8+lXx8kPPK9rG2j3oGydF0lyZP/bxmtfeefTo8Q+R/T1PP/3STwz/VwcPH0vPrqysWbsr8yNSpfw1mk7y50SSNtbz/2+F1WZs7W6q/L1SFN59JeXne1Xf2lw6L3xJkvFf23ett7nLX/vWmJWkxjjsusi/p0jS/f/2by87wzcFAEAgFAAAgVAAAARCAQAQCAUAQCAUAACBUAAABEIBABAIBQBAIBQAAIFQAACEfAFO5/WOFEbc2P+jaCfKzONuZvnikaLn7e5X+Z+03/M6TQZmL8yglz+J5cg8h4v5+eXlibX78JF8J1B/4PVe9c3r2TWz9GxZe/1e/cEoPzvzunWc12ZldGRJUml0Jbm9SmXpfYYtjV6govD+r8Rdmz/2rsv3wElSY9QwdfLeJzL4pgAACIQCACAQCgCAQCgAAAKhAAAIhAIAIBAKAIBAKAAAAqEAAAiEAgAgpJ9h75xn4+U9Yl4Zs5LUdfnnwIvG2z3s9dOzi/0Fa/cZC5vyu+fnrN1Do0JDksoqfw7XN8bW7l6Rr6JYWvB2z4+OpWdrr11AlfkRadYY9RKFd32qKl/R0W+9Co2qzF/7fuVVUcipuTA/k5bme1DPOPbSvPg9qxbDrNDo8vNdbXRiJPFNAQAQCAUAQCAUAACBUAAABEIBABAIBQBAIBQAAIFQAAAEQgEAEAgFAEAgFAAAId99ZFagVEZPSSWvn6hf5eeHZqfJ/CDfOXP6aN7avXmQnz9juGjtdjtqJpPV9OzqmtdPNFleT8+2GxNrd8+okakarxfGqrORNKjyPVn9Oa8nS6NhenQ486593c3Ss5W83YX1WvZem25XkmRc/9a8V6w+I+/GKo35ovPeO3N/PgAAzyMUAACBUAAABEIBABAIBQBAIBQAAIFQAAAEQgEAEAgFAEAgFAAAIV1zIeUfjZektnMe1W7M3fnZovVyr1Odnp2teI+vL63mqyXq4TFrd2FWOmys54/l8NHD1u4jSyvp2aXlZWv3bDW/uzZ+RkkqSq8yoLQaILzr0zmvidp7/ZRl/r5t2/zrQZLaJr+7NCs0SqM6R5I649jbxvs5S+N6lkYtjySVxo3lnpPUzhO+EQBwyiIUAACBUAAABEIBABAIBQBAIBQAAIFQAAAEQgEAEAgFAEAgFAAAgVAAAIR091HbrXmb23wfy8TsqNFsmh5dmZmdJrN8p8nj44m1u5vkz0ll5nVXez1MavNdVlPz51wbj9Oz63X+WkrStM5fn0l98vq6JKlT/np27cnrPqoLr/uoltN9ZK1W0eV7fkrzHi8Lr0OoX+X31zPvHne6rOaGA2vzcPNieraj+wgAcDIRCgCAQCgAAAKhAAAIhAIAIBAKAIBAKAAAAqEAAAiEAgAgEAoAgJCuuZjrexUAU6PqYOnw09bu5UMH07PdxHt8vTJ+zG7mnZOiNh7Tb71H+mXUC0hSr8s/pt/UXo3CzKg48UpIpNqoomiNOof/znxnHEtpVmiUzuUs+9ZulfnPgmVZWav7Vf5Y+lX67ee5YzFfEoVxzqdj7/Nx0+TrWSrzHBbG9Wnck5LANwUAQCAUAACBUAAABEIBABAIBQBAIBQAAIFQAAAEQgEAEAgFAEAgFAAAgVAAAIR0+cjQrNhomnz/TVnPrN31eCM9u768ZO0ujYqafjW0dve6fC9M13m9MEXh5XvRM47F6LORvI6aYeX1wgyM5UXhluWY48Y5dytqesbupu/dK53ROeR2H/WM69krze4js5tqZvSeHTnovQe1jdHaZV771vgNnXkOM/imAAAIhAIAIBAKAIBAKAAAAqEAAAiEAgAgEAoAgEAoAAACoQAACIQCACAYNRfe49Qz5R93XxjMWbvrhcX8cayuWbudJ+l7Pa/mYjTclJ4dDBas3VVvYM0XRnVFV3qfHXqD/L3SH5oVGr38fVWZFRqF2Ufg1GhUxutBkiqjXqJzulkkNUV+3q1PUesciDMstUZ1jiStLh3LH0rnXfvGuFcGbk2M89o035dTf/4J3wgAOGURCgCAQCgAAAKhAAAIhAIAIBAKAIBAKAAAAqEAAAiEAgAgEAoAgEAoAABCujijV3g9P8Mq32fUL7zenqrId4PMjfJ9Q5K0sb6Rnm1ary+lb3Q8bd66zdo9HHldSVOj06Yx+2+qfn6+6pvdLc4p9yqB/hvz+d/QurudrqTS6xCy5s1OIOdWKQrvuJumtubHk0l6dlZ7uzvjBy3NDi4ZnVpuX1cG3xQAAIFQAAAEQgEAEAgFAEAgFAAAgVAAAARCAQAQCAUAQCAUAACBUAAABEIBABDSxTPlzOzvaPLzXWn2Ks2fkZ/d8PpV2lm+V2k6mVm71eV7fsrK6wQqh15/1NxwlJ5tzP6b1igR6krvc4lzLE3XWLuLyuyRMfZ3ZvlRWRjz5mGXxjk3m6lUtfkOoXY6tnavLh225pePPpMfbqfW7k2b8j1mw6H3/laW+WtfKN/vlP7zT/hGAMApi1AAAARCAQAQCAUAQCAUAACBUAAABEIBABAIBQBAIBQAAIFQAACEfM1F4dVcTKb5x92rnvcY+MLmfBXFxrr3+Pp4LT/fdd7u6TT/SPry2oq1e77vFRLMDZx587ODca94JSSS07hRVN4923ZmJYrRRFGaLTGdccorc7nTitHW+dexJBVt/hxOxuvW7tXlI9b8eD3/GqpK79rPz+drLnpmzYVzXrrCew/K4JsCACAQCgCAQCgAAAKhAAAIhAIAIBAKAIBAKAAAAqEAAAiEAgAgEAoAgEAoAABCugBnYXHeWvyXw8+kZ6u+193S6w3Ss5tOX7R2z6b53pHxdMPavT4dp2fL2us0GbReR01t7C97+a6p536D0a7jlPxI6qy2JKflR2ob7xyWRb78yJmVpMIpVvJ+TDlHUtrtVPn56dS7x9fH3uut6Zr07NzcyNo9meWPfdZ5137W5I/b25zDNwUAQCAUAACBUAAABEIBABAIBQBAIBQAAIFQAAAEQgEAEAgFAEAgFAAAIV1zUfa8/Jg1s/Rs0fOe0+/P5WsXznr9Nmt3WeQfMV9eXrZ2r2yspGfb1fSlkSQVc/nqD0kqh/lqkWHlXR+n0aFtzY4Go0KjMD/zlIVX6dCvnP3e7q4zKjecSgxJzmfBovOOu5nlX/eTiVdbUdf53ZJXRbF42mbvWNr8+8R4bWLtrvr5175X+5LDNwUAQCAUAACBUAAABEIBABAIBQBAIBQAAIFQAAAEQgEAEAgFAEAgFAAAgVAAAIR0ycbK0mFr8fr6Unp2uDC0dm9M8x0oi3Pz1u5NmxfSs//6f3Zau+c35ftVyoHXZVTNz1nzXZfvEKoqr4epK/K9So1xHJJU9fPnpdfLd2RJUlMbfUOSCqOfqJmOrd2V0Tc1GHjX3qpKMjrMJKndyPcZbT/d6xt6+7lvseb/4z9+l549dMR7f+vK/OfpaZPvSXp+e37SKRpL4psCACAQCgCAQCgAAAKhAAAIhAIAIBAKAIBAKAAAAqEAAAiEAgAgEAoAgJDuL/jtw/9uLT66upyebb0WBfWG+fqCBbPmop7kH+s/c8uZ1u7ZNP+DriwftXYvj70ahZFxXrZu2WbtLo16ibq1VqswKjSKKj8r+Z+QutaogGi9Co2+US3STL3dTsXJeGPN2l2vr6ZnV5ePWbtnk4k1X1b5Kzocjazd63X+2tdmFUVdT9OzboFGBt8UAACBUAAABEIBABAIBQBAIBQAAIFQAAAEQgEAEAgFAEAgFAAAgVAAAARCAQAQ0gUrVZvvNJGk0xfyebNSe709W7aclp49563nWLsna/l+Faf6RpIGg3zf0JmDobX7yYPPWvO1UZfTK7zPDnOj/M9Z9Lziq8nU6Jwxi5VGI++cS4P0ZL+X7xuSpL7R27R0bMnarSZ/XjbNeZ1Ay+N8V9JwkD9/krS4MGfND0f/lJ6d37xg7T7wxFPp2Ycf+b/W7r5xXsrWLA/L7DzhGwEApyxCAQAQCAUAQCAUAACBUAAABEIBABAIBQBAIBQAAIFQAAAEQgEAEAgFAEBIF88sDo2yHElNmc+bfuH132iW72H6zwOPWqt7yvff9EuvK+dYfTQ9O5l5nSbLaxvWfFnlO22mq1Nr92lb8/PDhU3W7uk0fx9OnIInSU3rzc/q/M856Oe7jCRp3ugcmk7zfV2SNFnN9xMdnXm7pxvr6dnVZa+zqay8/qiFTUaf0dJha/fh5ZX0bNHrW7s7Y7bX93Zn8E0BABAIBQBAIBQAAIFQAAAEQgEAEAgFAEAgFAAAgVAAAARCAQAQCAUAQEj3S8xVM2txbTySXtfe7sEgX4vxL298nbW7cRodZl49R9Pk58e187C79M9v8OoiVlbz9QUbG971GVVOVYj3mP7QqC7YtjBn7e4NvGM5tpyvLWka7xx2Rf7z2vzCvLV78yh/XtZXzCqKxfz1mR9553t9PV/PIUlbzzwzPVuY137DeHlOn3zS2t3vD9KzbePV4WTwTQEAEAgFAEAgFAAAgVAAAARCAQAQCAUAQCAUAACBUAAABEIBABAIBQBAIBQAACFdxlO2Y2tx0ebLQdwOlGm9np790+8fsXaXXb53ZLaR73eSpLLKd85Mai+vl9fyXUaStLKSL3namDTW7v5olJ7dsv0sa/fp27elZ4dmJ5Aq75xP6vw5bDuv+6go8q+falZbuyfLK+nZJ/7f49butdX87oVN+ftEkgaDfKeWJD317DPp2aNrq9bucZvvHCp63vvbeJJ/rx2a92wG3xQAAIFQAAAEQgEAEAgFAEAgFAAAgVAAAARCAQAQCAUAQCAUAACBUAAAhHTNRd1W3uZ+Pm+62quL6Nr8Y/1F5e2ezjbyxyHv8fW2TZ9uTWb5x+glqSi8n3NoXM6Naf6cSNKkzlc6TDZtsnZvrC6kZ9vC+8zTG3jXszLurZ681089y5/DbsOrOFk/ciQ9O1nLV8pI3nHPZl5thfrePT426j8a8/p0yh9Lbb6WyzJ/LLPaqzhJ/fknfCMA4JRFKAAAAqEAAAiEAgAgEAoAgEAoAAACoQAACIQCACAQCgCAQCgAAAKhAAAI6TKeWTGyFneN0fdRdNZup6Wkbb3eEafPZto11u66znfUFJXXxdI3u1tKo0dm2vM+O0yMcz5eW7V290bz+eF+vmtKkjrvNlTVy59Ds4JLRZ0/h9OVNWv3dHkpPdtNx9bu0TD/PjGYN66lpNrssqqVP4dtObB2l8buqvHeJxqjs8l978zgmwIAIBAKAIBAKAAAAqEAAAiEAgAgEAoAgEAoAAACoQAACIQCACAQCgCAkO4BcOsiVOYfv+6MR8afmzce7W69x8A741CsKg9JTW08vi7zsfvWq7kojN6F0dD77DDdyNd5rK+tWLt7RjXCcNOCtVtD75wXRrVIXc+s3Wur+fqPjaVj3u61fC1GWXrXfm5+Lj9cmbUVTv2DpLbN10s0ZhVFa7z2rfcrSUVhdKIU3us+g28KAIBAKAAAAqEAAAiEAgAgEAoAgEAoAAACoQAACIQCACAQCgCAQCgAAAKhAAAI6e6jzqjjkCRr3KsGMZd7/USF8YNWbh+U0X1kVs6oKNKX8rn9/X5+dvPQ2t0U+fMyXhtbu1eWjqZnB04Pj6T+0DuHVZU/L7XRwyNJ6+v5fqKVlSVrd9Pk78P+0Lv2o7n8fGve5JPae6Nom3zf1GyS7+uSpNp46fd67n2V7zPqvDfDFL4pAAACoQAACIQCACAQCgCAQCgAAAKhAAAIhAIAIBAKAIBAKAAAAqEAAAjp56/d2gWni6Io3OX5Z8xbM/eKMn/cXWlWaDT5+V7lPdJflWZXiHHsw4FXdaBe/jH99XbZWr0yXknPLh09bO3uD/LVH5LU7+fvrdLscimM+Vmbr62QvNeye06KwqldMGtizPnOOi/e7tI4idYpMRXKv9ay+KYAAAiEAgAgEAoAgEAoAAACoQAACIQCACAQCgCAQCgAAAKhAAAIhAIAIBAKAICQ7j7y5btbnJ6X539DWtl5xSN1lz+WtjW7WLp8F0tbz6zdZd/8OWfG/oG3ezgapWdP27xg7Z616+nZ9ZUla/eS2300yPfO9Crv89fqWr7jaTzesHbPVfnrWRo9VpLUdI0xa3YfGa+f5+bzxzIyr31jfJ5u3W434z2rcN4Mk/imAAAIhAIAIBAKAIBAKAAAAqEAAAiEAgAgEAoAgEAoAAACoQAACIQCACAQCgCAkO4+6syeksKo5DDqhmydmXtFYXQ2GbOSNBjmO4E6s7PJVRj9N51d3ZK/V+bn8+dEkk5v8wdz6Fi+P0iS1paPWfODXv5Y5hfmrN2rS/ljqRuvE6iay/dNDeeG1m7n2s8mE2t3W0+t+dI4luGC18FVt/nXz3TmvU/UrfEedBLeO/mmAAAIhAIAIBAKAIBAKAAAAqEAAAiEAgAgEAoAgEAoAAACoQAACIQCACCkay6c2gqX+6R2J+dgvAPvnE6H0svUqlelZxvjUXdJasxajNY4drdxo2vyx16a53B+Ll8XsTjx6h9W1r3ahSMHD6ZnN9a8Oo96Yy09Oxz0rd0jo3Kj7Jn3VZuvlmg67/rInO8bxz4aDqzddZPfPWu8eo52lv85T8b7Mt8UAACBUAAABEIBABAIBQBAIBQAAIFQAAAEQgEAEAgFAEAgFAAAgVAAAARCAQAQ0t1HZZHvNJG8fqLOLNdx5jsz92Z1k56d1N45mUzznSaN0SEjSSq8n9M5L1Wb72ySpKpM31aq3PIW49r3e2YnUM875+tGP9HqZGztrsr8sWyaX7B2F2X+HE6nXm9Pp1l6tjKOQ5KGw/x9JUlFne/g6pr8616SprP8/MzoMpKkps3vLuQddwbfFAAAgVAAAARCAQAQCAUAQCAUAACBUAAABEIBABAIBQBAIBQAAIFQAACE/HPjRf6R8ed/gzlvMA7FqduQpK4yqhGMx9ElqTEOZdbl6wIkqWu969MpX6NQld7uXmfMmx9LnPaPovOWu5UbpXHO69a7noNh/tgXFuat3f3RMD3bmsftVND0el59SiOvLqKd5Oe7znst13X+vLSdW1mTn2/Neo4MvikAAAKhAAAIhAIAIBAKAIBAKAAAAqEAAAiEAgAgEAoAgEAoAAACoQAACIQCACDku4/M/LA6h9xaJYvZ29PLdx+V1cA7lCLfU7IxnVqrpzOvF6Zu8v0qZi2MWmN3W3rLyzZ/H5bmtS/NHhmnuafqefdKWebvw95gztq9sHlTeraerVu7uzp/39b12No9bbz3oF4v//Y2M9/fitK4D83eOKfGrChPfMcc3xQAAIFQAAAEQgEAEAgFAEAgFAAAgVAAAARCAQAQCAUAQCAUAACBUAAAhPRz4G3hPNQvdZ3zrLa1WqWz25mV1LX5uoiyHFq7nR+zcE9Kd/KuT2HullHR0FllEVJhnJaqzddtSFKv9WouesatNTXqOSRJZb66YqaRtbo2ro9ThyJJfeXPYWnMPsd8LRtVFLV7KMbuoph5u51eGecFkcQ3BQBAIBQAAIFQAAAEQgEAEAgFAEAgFAAAgVAAAARCAQAQCAUAQCAUAACBUAAAhKKzSooAAP+T8U0BABAIBQBAIBQAAIFQAAAEQgEAEAgFAEAgFAAAgVAAAARCAQAQ/j+OkCL+41cl5AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from dataset_loading.dataset_loading import TrafficSignDataset, simple_transform  # Use relative import\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images...\n",
      "Found 4222 images.\n"
     ]
    }
   ],
   "source": [
    "dataset = TrafficSignDataset(img_dir=r'C:\\Users\\delta\\OneDrive\\Desktop\\Minor_Project_Code\\CNN\\Indian-Traffic Sign-Dataset\\Images_custom', transform=simple_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for i in range(len(dataset)):\n",
    "    img, label = dataset.__getitem__(i)\n",
    "    images.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(32, 32, 3)))\n",
    "    # CNN layers with padding and batch normalization\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Dropout layer to prevent overfitting\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "\n",
    "    # Add the dropout after dense layer to prevent some overfitting\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    \n",
    "    model.add(layers.Dense(len(np.unique(labels)), activation='softmax'))  # Number of classes\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,967</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │         \u001b[38;5;34m7,967\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">605,983</span> (2.31 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m605,983\u001b[0m (2.31 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">603,871</span> (2.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m603,871\u001b[0m (2.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> (8.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,112\u001b[0m (8.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.0811 - loss: 4.3072 - val_accuracy: 0.0784 - val_loss: 3.6207\n",
      "Epoch 2/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.1931 - loss: 3.2790 - val_accuracy: 0.1405 - val_loss: 6.3895\n",
      "Epoch 3/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.2450 - loss: 2.8523 - val_accuracy: 0.3536 - val_loss: 2.1609\n",
      "Epoch 4/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.2825 - loss: 2.6894 - val_accuracy: 0.4127 - val_loss: 1.9539\n",
      "Epoch 5/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3180 - loss: 2.3557 - val_accuracy: 0.4112 - val_loss: 1.8986\n",
      "Epoch 6/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.3556 - loss: 2.1933 - val_accuracy: 0.3757 - val_loss: 2.0691\n",
      "Epoch 7/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.4102 - loss: 1.9482 - val_accuracy: 0.5385 - val_loss: 1.4942\n",
      "Epoch 8/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.4460 - loss: 1.8120 - val_accuracy: 0.5710 - val_loss: 1.2873\n",
      "Epoch 9/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.4922 - loss: 1.6555 - val_accuracy: 0.4778 - val_loss: 1.7038\n",
      "Epoch 10/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.5254 - loss: 1.5085 - val_accuracy: 0.5873 - val_loss: 1.2108\n",
      "Epoch 11/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.5718 - loss: 1.3916 - val_accuracy: 0.6464 - val_loss: 1.0968\n",
      "Epoch 12/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.5991 - loss: 1.2694 - val_accuracy: 0.6864 - val_loss: 0.9894\n",
      "Epoch 13/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.6530 - loss: 1.1194 - val_accuracy: 0.7175 - val_loss: 1.0940\n",
      "Epoch 14/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.6762 - loss: 1.0848 - val_accuracy: 0.5163 - val_loss: 1.5469\n",
      "Epoch 15/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.6712 - loss: 1.0737 - val_accuracy: 0.7337 - val_loss: 0.8710\n",
      "Epoch 16/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - accuracy: 0.7424 - loss: 0.8705 - val_accuracy: 0.7426 - val_loss: 0.7679\n",
      "Epoch 17/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7390 - loss: 0.8851 - val_accuracy: 0.8033 - val_loss: 0.6618\n",
      "Epoch 18/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7569 - loss: 0.7863 - val_accuracy: 0.8417 - val_loss: 0.5564\n",
      "Epoch 19/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.7891 - loss: 0.7402 - val_accuracy: 0.8299 - val_loss: 0.5729\n",
      "Epoch 20/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.7938 - loss: 0.6416 - val_accuracy: 0.8299 - val_loss: 0.6171\n",
      "Epoch 21/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.7967 - loss: 0.6582 - val_accuracy: 0.8284 - val_loss: 0.6463\n",
      "Epoch 22/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8338 - loss: 0.5444 - val_accuracy: 0.8284 - val_loss: 0.6101\n",
      "Epoch 23/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8418 - loss: 0.5098 - val_accuracy: 0.7811 - val_loss: 0.7513\n",
      "Epoch 24/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8167 - loss: 0.6249 - val_accuracy: 0.8891 - val_loss: 0.4003\n",
      "Epoch 25/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8712 - loss: 0.4617 - val_accuracy: 0.8861 - val_loss: 0.3842\n",
      "Epoch 26/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8840 - loss: 0.3851 - val_accuracy: 0.8891 - val_loss: 0.4251\n",
      "Epoch 27/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8631 - loss: 0.4626 - val_accuracy: 0.8831 - val_loss: 0.4960\n",
      "Epoch 28/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8756 - loss: 0.4128 - val_accuracy: 0.8905 - val_loss: 0.4249\n",
      "Epoch 29/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8747 - loss: 0.4019 - val_accuracy: 0.8935 - val_loss: 0.3928\n",
      "Epoch 30/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8913 - loss: 0.3281 - val_accuracy: 0.8328 - val_loss: 0.6019\n",
      "Epoch 31/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8869 - loss: 0.3875 - val_accuracy: 0.8728 - val_loss: 0.5443\n",
      "Epoch 32/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.9027 - loss: 0.3183 - val_accuracy: 0.8654 - val_loss: 0.4962\n",
      "Epoch 33/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9040 - loss: 0.3123 - val_accuracy: 0.9068 - val_loss: 0.5420\n",
      "Epoch 34/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9094 - loss: 0.2901 - val_accuracy: 0.8876 - val_loss: 0.4456\n",
      "Epoch 35/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9163 - loss: 0.2777 - val_accuracy: 0.8861 - val_loss: 0.4861\n",
      "Epoch 36/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9279 - loss: 0.2427 - val_accuracy: 0.9009 - val_loss: 0.4280\n",
      "Epoch 37/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9030 - loss: 0.3213 - val_accuracy: 0.8787 - val_loss: 0.5115\n",
      "Epoch 38/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9387 - loss: 0.2157 - val_accuracy: 0.9068 - val_loss: 0.4015\n",
      "Epoch 39/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9408 - loss: 0.1838 - val_accuracy: 0.8802 - val_loss: 0.5125\n",
      "Epoch 40/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9332 - loss: 0.2244 - val_accuracy: 0.8994 - val_loss: 0.5114\n",
      "Epoch 41/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9421 - loss: 0.1941 - val_accuracy: 0.9068 - val_loss: 0.4133\n",
      "Epoch 42/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9372 - loss: 0.2046 - val_accuracy: 0.8979 - val_loss: 0.4571\n",
      "Epoch 43/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9244 - loss: 0.2340 - val_accuracy: 0.9098 - val_loss: 0.4167\n",
      "Epoch 44/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9355 - loss: 0.2076 - val_accuracy: 0.9172 - val_loss: 0.3998\n",
      "Epoch 45/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9496 - loss: 0.1645 - val_accuracy: 0.9201 - val_loss: 0.3635\n",
      "Epoch 46/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9436 - loss: 0.1773 - val_accuracy: 0.9127 - val_loss: 0.4297\n",
      "Epoch 47/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9522 - loss: 0.1658 - val_accuracy: 0.9290 - val_loss: 0.3713\n",
      "Epoch 48/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9556 - loss: 0.1562 - val_accuracy: 0.9053 - val_loss: 0.4736\n",
      "Epoch 49/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9504 - loss: 0.1539 - val_accuracy: 0.9068 - val_loss: 0.4542\n",
      "Epoch 50/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9452 - loss: 0.1996 - val_accuracy: 0.9216 - val_loss: 0.3794\n",
      "Epoch 51/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9510 - loss: 0.1784 - val_accuracy: 0.9068 - val_loss: 0.4453\n",
      "Epoch 52/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9575 - loss: 0.1482 - val_accuracy: 0.9053 - val_loss: 0.4897\n",
      "Epoch 53/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9494 - loss: 0.1681 - val_accuracy: 0.9186 - val_loss: 0.4542\n",
      "Epoch 54/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9592 - loss: 0.1578 - val_accuracy: 0.9216 - val_loss: 0.3539\n",
      "Epoch 55/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9578 - loss: 0.1494 - val_accuracy: 0.9098 - val_loss: 0.3971\n",
      "Epoch 56/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9534 - loss: 0.1543 - val_accuracy: 0.9216 - val_loss: 0.3887\n",
      "Epoch 57/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9798 - loss: 0.0839 - val_accuracy: 0.9098 - val_loss: 0.4167\n",
      "Epoch 58/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9583 - loss: 0.1301 - val_accuracy: 0.9157 - val_loss: 0.4145\n",
      "Epoch 59/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9578 - loss: 0.1498 - val_accuracy: 0.8891 - val_loss: 0.5273\n",
      "Epoch 60/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9424 - loss: 0.1897 - val_accuracy: 0.9142 - val_loss: 0.4714\n",
      "Epoch 61/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9623 - loss: 0.1352 - val_accuracy: 0.9172 - val_loss: 0.4447\n",
      "Epoch 62/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9658 - loss: 0.1204 - val_accuracy: 0.9201 - val_loss: 0.4304\n",
      "Epoch 63/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9672 - loss: 0.0959 - val_accuracy: 0.9112 - val_loss: 0.5121\n",
      "Epoch 64/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9749 - loss: 0.0836 - val_accuracy: 0.9024 - val_loss: 0.4194\n",
      "Epoch 65/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9653 - loss: 0.1033 - val_accuracy: 0.9275 - val_loss: 0.3718\n",
      "Epoch 66/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9688 - loss: 0.1181 - val_accuracy: 0.9216 - val_loss: 0.4261\n",
      "Epoch 67/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9548 - loss: 0.1528 - val_accuracy: 0.8979 - val_loss: 0.5331\n",
      "Epoch 68/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9600 - loss: 0.1487 - val_accuracy: 0.9231 - val_loss: 0.4445\n",
      "Epoch 69/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9668 - loss: 0.1066 - val_accuracy: 0.9127 - val_loss: 0.4652\n",
      "Epoch 70/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9683 - loss: 0.1124 - val_accuracy: 0.9246 - val_loss: 0.4313\n",
      "Epoch 71/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9666 - loss: 0.1135 - val_accuracy: 0.9038 - val_loss: 0.5165\n",
      "Epoch 72/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9597 - loss: 0.1378 - val_accuracy: 0.9157 - val_loss: 0.4394\n",
      "Epoch 73/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9528 - loss: 0.1305 - val_accuracy: 0.8994 - val_loss: 0.5169\n",
      "Epoch 74/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9633 - loss: 0.1276 - val_accuracy: 0.9127 - val_loss: 0.4848\n",
      "Epoch 75/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9821 - loss: 0.0709 - val_accuracy: 0.9127 - val_loss: 0.4277\n",
      "Epoch 76/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9744 - loss: 0.0714 - val_accuracy: 0.7988 - val_loss: 0.9803\n",
      "Epoch 77/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9624 - loss: 0.1388 - val_accuracy: 0.8994 - val_loss: 0.5763\n",
      "Epoch 78/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.9709 - loss: 0.1144 - val_accuracy: 0.9231 - val_loss: 0.3942\n",
      "Epoch 79/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.9735 - loss: 0.0792 - val_accuracy: 0.9068 - val_loss: 0.5570\n",
      "Epoch 80/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.9741 - loss: 0.0850 - val_accuracy: 0.9127 - val_loss: 0.5158\n",
      "Epoch 81/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.1163 - val_accuracy: 0.9216 - val_loss: 0.4895\n",
      "Epoch 82/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9786 - loss: 0.0820 - val_accuracy: 0.9216 - val_loss: 0.5081\n",
      "Epoch 83/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9722 - loss: 0.0818 - val_accuracy: 0.9127 - val_loss: 0.5277\n",
      "Epoch 84/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9799 - loss: 0.0811 - val_accuracy: 0.9083 - val_loss: 0.5842\n",
      "Epoch 85/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9710 - loss: 0.0857 - val_accuracy: 0.9068 - val_loss: 0.5969\n",
      "Epoch 86/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9792 - loss: 0.0824 - val_accuracy: 0.9260 - val_loss: 0.4425\n",
      "Epoch 87/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9755 - loss: 0.1069 - val_accuracy: 0.9068 - val_loss: 0.5141\n",
      "Epoch 88/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9646 - loss: 0.1256 - val_accuracy: 0.9098 - val_loss: 0.4577\n",
      "Epoch 89/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9838 - loss: 0.0589 - val_accuracy: 0.9201 - val_loss: 0.4181\n",
      "Epoch 90/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9779 - loss: 0.0844 - val_accuracy: 0.9112 - val_loss: 0.5400\n",
      "Epoch 91/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9764 - loss: 0.0782 - val_accuracy: 0.9024 - val_loss: 0.5833\n",
      "Epoch 92/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9723 - loss: 0.0994 - val_accuracy: 0.9216 - val_loss: 0.5093\n",
      "Epoch 93/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9713 - loss: 0.0818 - val_accuracy: 0.9142 - val_loss: 0.4973\n",
      "Epoch 94/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9808 - loss: 0.0604 - val_accuracy: 0.9216 - val_loss: 0.4965\n",
      "Epoch 95/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9706 - loss: 0.1105 - val_accuracy: 0.9186 - val_loss: 0.4872\n",
      "Epoch 96/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9800 - loss: 0.0628 - val_accuracy: 0.9172 - val_loss: 0.4634\n",
      "Epoch 97/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9801 - loss: 0.0578 - val_accuracy: 0.9172 - val_loss: 0.5165\n",
      "Epoch 98/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9772 - loss: 0.0673 - val_accuracy: 0.9201 - val_loss: 0.5111\n",
      "Epoch 99/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9720 - loss: 0.0922 - val_accuracy: 0.9142 - val_loss: 0.5741\n",
      "Epoch 100/100\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9805 - loss: 0.0740 - val_accuracy: 0.9260 - val_loss: 0.5199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27855dd4da0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=8, validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "Test Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('cnn_model_custom_2.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = tf.keras.models.load_model(model_path)\n",
    "input_shape = model.input_shape\n",
    "print(f\"Model input shape: {input_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results for First 10 Epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Val_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1174</td>\n",
       "      <td>3.9373</td>\n",
       "      <td>0.0459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2956</td>\n",
       "      <td>2.7174</td>\n",
       "      <td>0.2101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>2.1798</td>\n",
       "      <td>0.4275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.4598</td>\n",
       "      <td>1.9039</td>\n",
       "      <td>0.5710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5564</td>\n",
       "      <td>1.4427</td>\n",
       "      <td>0.6109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.6274</td>\n",
       "      <td>1.2193</td>\n",
       "      <td>0.6583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.6647</td>\n",
       "      <td>1.0747</td>\n",
       "      <td>0.7618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.6922</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.6953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.7774</td>\n",
       "      <td>0.7811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.8121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Accuracy    Loss  Val_Accuracy\n",
       "0      1    0.1174  3.9373        0.0459\n",
       "1      2    0.2956  2.7174        0.2101\n",
       "2      3    0.4008  2.1798        0.4275\n",
       "3      4    0.4598  1.9039        0.5710\n",
       "4      5    0.5564  1.4427        0.6109\n",
       "5      6    0.6274  1.2193        0.6583\n",
       "6      7    0.6647  1.0747        0.7618\n",
       "7      8    0.6922  0.9989        0.6953\n",
       "8      9    0.7541  0.7774        0.7811\n",
       "9     10    0.7913  0.6942        0.8121"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create data dictionary for the first 10 epochs\n",
    "data = {\n",
    "    'Epoch': range(1, 11),\n",
    "    'Accuracy': [0.1174, 0.2956, 0.4008, 0.4598, 0.5564, 0.6274, 0.6647, 0.6922, 0.7541, 0.7913],\n",
    "    'Loss': [3.9373, 2.7174, 2.1798, 1.9039, 1.4427, 1.2193, 1.0747, 0.9989, 0.7774, 0.6942],\n",
    "    'Val_Accuracy': [0.0459, 0.2101, 0.4275, 0.5710, 0.6109, 0.6583, 0.7618, 0.6953, 0.7811, 0.8121]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Format the values to 4 decimal places\n",
    "df = df.round(4)\n",
    "\n",
    "# Display the table\n",
    "print(\"Training Results for First 10 Epochs\")\n",
    "display(df)\n",
    "\n",
    "# Optionally, save to CSV for research paper\n",
    "df.to_csv('training_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
